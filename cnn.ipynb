{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b76ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import OrganAMNIST, INFO, Evaluator\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn.neighbors\n",
    "import sklearn.metrics\n",
    "import skimage.transform\n",
    "import skimage.util\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim, inference_mode\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb57b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "data_flag = 'organamnist'\n",
    "info = INFO[data_flag]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(degrees=15),  # Rotate image by up to 15 degrees\n",
    "    transforms.\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "train_data = DataClass(split='train', transform=train_transform, download=True)\n",
    "val_data = DataClass(split='val', transform=eval_transform, download=True)\n",
    "test_data = DataClass(split='test', transform=eval_transform, download=True)\n",
    "\n",
    "# change data into dataloader form\n",
    "BATCH_SIZE = 128\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# understanding the dataset\n",
    "# Number of image channels\n",
    "n_channels = info['n_channels']\n",
    "# print(f\"number of channels: {n_channels}\")\n",
    "\n",
    "# Number of classes\n",
    "n_classes = len(info['label'])\n",
    "# print(f\"number of classes: {n_classes}\")\n",
    "\n",
    "# Get the class names from the dataset\n",
    "class_names = info['label']\n",
    "# print(f\"class names: {class_names}\")\n",
    "\n",
    "\n",
    "# define model\n",
    "class cnn(torch.nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, \n",
    "                         stride=2))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units*4, \n",
    "                      kernel_size=3),\n",
    "            nn.BatchNorm2d(hidden_units*4),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units*4, \n",
    "                      out_channels=hidden_units*4, \n",
    "                      kernel_size=3),\n",
    "            nn.BatchNorm2d(hidden_units*4),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units*4, \n",
    "                      out_channels=hidden_units*4, \n",
    "                      kernel_size=3,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(hidden_units*4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, \n",
    "                         stride=2))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_units*4 * 4 * 4, hidden_units*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units*8, hidden_units*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units*8, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c573951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define training loop helper functions\n",
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # need to change target shape for this medmnist data \n",
    "        # y = y.squeeze().long()\n",
    "        y = y.view(-1).long()\n",
    "\n",
    "        \n",
    "        # Send data to selected device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. loss and accuracy\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch \n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "            model: torch.nn.Module,\n",
    "            loss_fn: torch.nn.Module,\n",
    "            accuracy_fn,\n",
    "            device: torch.device = device):\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval() # eval mode for testing\n",
    "    with torch.inference_mode(): # Inference context manager\n",
    "        for X, y in data_loader:\n",
    "            # need to change target shape for this medmnist data \n",
    "            # y = y.squeeze().long()\n",
    "            y = y.view(-1).long()\n",
    "\n",
    "            \n",
    "            # Send data to selected device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                                    y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        \n",
    "        return test_loss, test_acc\n",
    "    \n",
    "def eval_func(data_loader: torch.utils.data.DataLoader,\n",
    "            model: torch.nn.Module,\n",
    "            loss_fn: torch.nn.Module,\n",
    "            accuracy_fn,\n",
    "            device: torch.device = device):\n",
    "\n",
    "    eval_loss, eval_acc = 0, 0\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    y_preds = []\n",
    "    y_targets = []\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in tqdm(enumerate(data_loader)):\n",
    "            # need to change target shape for this medmnist data \n",
    "            y = y.squeeze().long()\n",
    "            \n",
    "            # Send data to selected device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            eval_pred = model(X)\n",
    "            \n",
    "            # Find loss and accuracy\n",
    "            eval_loss += loss_fn(eval_pred, y)\n",
    "            eval_acc += accuracy_fn(y_true=y,\n",
    "                                    y_pred=eval_pred.argmax(dim=1))\n",
    "\n",
    "            # Add prediction and target labels to list\n",
    "            eval_labels = torch.argmax(torch.softmax(eval_pred, dim=1), dim=1)\n",
    "            y_preds.append(eval_labels)\n",
    "            y_targets.append(y)\n",
    "\n",
    "        # Scale loss and acc \n",
    "        eval_loss /= len(data_loader)\n",
    "        eval_acc /= len(data_loader)\n",
    "        \n",
    "        # Put predictions on CPU for evaluation\n",
    "        y_preds=torch.cat(y_preds).cpu() \n",
    "        y_targets=torch.cat(y_targets).cpu() \n",
    "        \n",
    "        return {\"model_name\": model.__class__.__name__, \n",
    "            \"loss\": eval_loss.item(),\n",
    "            \"accuracy\": eval_acc,\n",
    "            \"predictions\": y_preds,\n",
    "            \"targets\": y_targets}\n",
    "    \n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() \n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc\n",
    "\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3cbcb1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354caca3e5a14088bc82f82ed13b18c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training loss: 0.582 | Training acc: 79.12 | Test loss: 0.567 | Test acc: 81.98\n",
      "Saving best model for epoch: 0\n",
      "Epoch: 1 | Training loss: 0.329 | Training acc: 88.47 | Test loss: 0.463 | Test acc: 85.37\n",
      "Saving best model for epoch: 1\n",
      "Epoch: 2 | Training loss: 0.172 | Training acc: 94.02 | Test loss: 0.518 | Test acc: 84.51\n",
      "Epoch: 3 | Training loss: 0.129 | Training acc: 95.45 | Test loss: 0.933 | Test acc: 76.87\n",
      "Epoch: 4 | Training loss: 0.174 | Training acc: 94.20 | Test loss: 0.806 | Test acc: 80.59\n",
      "Epoch: 5 | Training loss: 0.117 | Training acc: 96.06 | Test loss: 0.493 | Test acc: 87.34\n",
      "Epoch: 6 | Training loss: 0.071 | Training acc: 97.59 | Test loss: 0.520 | Test acc: 86.70\n",
      "Epoch: 7 | Training loss: 0.057 | Training acc: 98.00 | Test loss: 0.750 | Test acc: 83.69\n",
      "Epoch: 8 | Training loss: 0.061 | Training acc: 97.93 | Test loss: 0.595 | Test acc: 86.44\n",
      "Epoch: 9 | Training loss: 0.062 | Training acc: 97.84 | Test loss: 0.527 | Test acc: 87.36\n",
      "Train time on cpu: 270.369 seconds\n"
     ]
    }
   ],
   "source": [
    "#CNN with Adam optimizer and image preprocessing\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "data_flag = 'organamnist'\n",
    "info = INFO[data_flag]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(degrees=15),  # Rotate image by up to 15 degrees\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "train_data = DataClass(split='train', transform=train_transform, download=True)\n",
    "val_data = DataClass(split='val', transform=eval_transform, download=True)\n",
    "test_data = DataClass(split='test', transform=eval_transform, download=True)\n",
    "\n",
    "# change data into dataloader form\n",
    "BATCH_SIZE = 128\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# define Model\n",
    "model = cnn(input_shape=n_channels, \n",
    "                     hidden_units=16,\n",
    "                     output_shape=n_classes).to(device)\n",
    "\n",
    "\n",
    "# setup loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# view Model\n",
    "# model\n",
    "\n",
    "# test performance\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# measure Time\n",
    "train_time_start_model = timer()\n",
    "iteration_loss_list = []\n",
    "iteration_accuracy_list = []\n",
    "\n",
    "# set parameters\n",
    "epochs = 10\n",
    "best_loss = 10\n",
    "\n",
    "# call train and test function\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(data_loader=train_dataloader,\n",
    "                                       model=model,\n",
    "                                       loss_fn = loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       accuracy_fn=accuracy_fn,\n",
    "                                       device=device)\n",
    "    \n",
    "    test_loss, test_acc = test_step(data_loader=test_dataloader,\n",
    "                                    model=model,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    accuracy_fn=accuracy_fn,\n",
    "                                    device=device)\n",
    "    \n",
    "    for iteration, (x, y) in enumerate(train_dataloader):\n",
    "        iteration_loss_list.append(train_loss.item())\n",
    "        iteration_accuracy_list.append(train_acc)\n",
    "\n",
    "    \n",
    "    print(f\"Epoch: {epoch} | Training loss: {train_loss:.3f} | Training acc: {train_acc:.2f} | Test loss: {test_loss:.3f} | Test acc: {test_acc:.2f}\")\n",
    "\n",
    "    # save best model instance\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        print(f\"Saving best model for epoch: {epoch}\")\n",
    "        torch.save(obj=model.state_dict(), \n",
    "                   f=\"./model.pth\")     \n",
    "train_time_end_model = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_model,\n",
    "                                           end=train_time_end_model,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e744f3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca0cc28a8a2438bad57b47ed8e0a758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training loss: 1.652 | Training acc: 41.80 | Test loss: 1.271 | Test acc: 59.63\n",
      "Saving best model for epoch: 0\n",
      "Epoch: 1 | Training loss: 0.720 | Training acc: 75.12 | Test loss: 0.810 | Test acc: 72.57\n",
      "Saving best model for epoch: 1\n",
      "Epoch: 2 | Training loss: 0.426 | Training acc: 85.38 | Test loss: 0.702 | Test acc: 76.90\n",
      "Saving best model for epoch: 2\n",
      "Epoch: 3 | Training loss: 0.311 | Training acc: 88.83 | Test loss: 1.306 | Test acc: 62.15\n",
      "Epoch: 4 | Training loss: 0.305 | Training acc: 89.44 | Test loss: 0.706 | Test acc: 79.22\n",
      "Epoch: 5 | Training loss: 0.204 | Training acc: 92.96 | Test loss: 0.668 | Test acc: 80.58\n",
      "Saving best model for epoch: 5\n",
      "Epoch: 6 | Training loss: 0.161 | Training acc: 94.51 | Test loss: 0.581 | Test acc: 83.22\n",
      "Saving best model for epoch: 6\n",
      "Epoch: 7 | Training loss: 0.136 | Training acc: 95.29 | Test loss: 0.614 | Test acc: 82.64\n",
      "Epoch: 8 | Training loss: 0.117 | Training acc: 95.86 | Test loss: 0.580 | Test acc: 82.89\n",
      "Saving best model for epoch: 8\n",
      "Epoch: 9 | Training loss: 0.097 | Training acc: 96.65 | Test loss: 0.597 | Test acc: 83.52\n",
      "Train time on cpu: 272.922 seconds\n"
     ]
    }
   ],
   "source": [
    "#CNN with SGD optimizer and image preprocessing\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "data_flag = 'organamnist'\n",
    "info = INFO[data_flag]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(degrees=15),  # Rotate image by up to 15 degrees\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "train_data = DataClass(split='train', transform=train_transform, download=True)\n",
    "val_data = DataClass(split='val', transform=eval_transform, download=True)\n",
    "test_data = DataClass(split='test', transform=eval_transform, download=True)\n",
    "\n",
    "# change data into dataloader form\n",
    "BATCH_SIZE = 128\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# define Model\n",
    "model = cnn(input_shape=n_channels, \n",
    "                     hidden_units=16,\n",
    "                     output_shape=n_classes).to(device)\n",
    "\n",
    "\n",
    "# setup loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# view Model\n",
    "# model\n",
    "\n",
    "# test performance\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# measure Time\n",
    "train_time_start_model = timer()\n",
    "iteration_loss_list = []\n",
    "iteration_accuracy_list = []\n",
    "\n",
    "# set parameters\n",
    "epochs = 10\n",
    "best_loss = 10\n",
    "\n",
    "# call train and test function\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(data_loader=train_dataloader,\n",
    "                                       model=model,\n",
    "                                       loss_fn = loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       accuracy_fn=accuracy_fn,\n",
    "                                       device=device)\n",
    "    \n",
    "    test_loss, test_acc = test_step(data_loader=test_dataloader,\n",
    "                                    model=model,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    accuracy_fn=accuracy_fn,\n",
    "                                    device=device)\n",
    "    \n",
    "    for iteration, (x, y) in enumerate(train_dataloader):\n",
    "        iteration_loss_list.append(train_loss.item())\n",
    "        iteration_accuracy_list.append(train_acc)\n",
    "\n",
    "    \n",
    "    print(f\"Epoch: {epoch} | Training loss: {train_loss:.3f} | Training acc: {train_acc:.2f} | Test loss: {test_loss:.3f} | Test acc: {test_acc:.2f}\")\n",
    "\n",
    "    # save best model instance\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        print(f\"Saving best model for epoch: {epoch}\")\n",
    "        torch.save(obj=model.state_dict(), \n",
    "                   f=\"./model.pth\")     \n",
    "train_time_end_model = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_model,\n",
    "                                           end=train_time_end_model,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2d07ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62a6211f12545cdb691cf5519209371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training loss: 1.646 | Training acc: 41.98 | Test loss: 1.264 | Test acc: 59.67\n",
      "Saving best model for epoch: 0\n",
      "Epoch: 1 | Training loss: 0.684 | Training acc: 76.36 | Test loss: 0.759 | Test acc: 74.99\n",
      "Saving best model for epoch: 1\n",
      "Epoch: 2 | Training loss: 0.374 | Training acc: 87.38 | Test loss: 4.176 | Test acc: 35.00\n",
      "Epoch: 3 | Training loss: 0.503 | Training acc: 83.82 | Test loss: 0.643 | Test acc: 79.71\n",
      "Saving best model for epoch: 3\n",
      "Epoch: 4 | Training loss: 0.226 | Training acc: 92.34 | Test loss: 0.698 | Test acc: 79.31\n",
      "Epoch: 5 | Training loss: 0.160 | Training acc: 94.57 | Test loss: 0.625 | Test acc: 82.32\n",
      "Saving best model for epoch: 5\n",
      "Epoch: 6 | Training loss: 0.115 | Training acc: 96.03 | Test loss: 0.601 | Test acc: 83.15\n",
      "Saving best model for epoch: 6\n",
      "Epoch: 7 | Training loss: 0.090 | Training acc: 97.02 | Test loss: 0.660 | Test acc: 83.56\n",
      "Epoch: 8 | Training loss: 0.062 | Training acc: 97.94 | Test loss: 0.677 | Test acc: 83.98\n",
      "Epoch: 9 | Training loss: 0.052 | Training acc: 98.26 | Test loss: 0.817 | Test acc: 82.61\n",
      "Train time on cpu: 210.326 seconds\n"
     ]
    }
   ],
   "source": [
    "#CNN with SGD optimizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "data_flag = 'organamnist'\n",
    "info = INFO[data_flag]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "train_data = DataClass(split='train', transform=data_transform, download=True)\n",
    "val_data = DataClass(split='val', transform=data_transform, download=True)\n",
    "test_data = DataClass(split='test', transform=data_transform, download=True)\n",
    "\n",
    "# change data into dataloader form\n",
    "BATCH_SIZE = 128\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# define Model\n",
    "model = cnn(input_shape=n_channels, \n",
    "                     hidden_units=16,\n",
    "                     output_shape=n_classes).to(device)\n",
    "\n",
    "\n",
    "# setup loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# view Model\n",
    "# model\n",
    "\n",
    "# test performance\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# measure Time\n",
    "train_time_start_model = timer()\n",
    "iteration_loss_list = []\n",
    "iteration_accuracy_list = []\n",
    "\n",
    "# set parameters\n",
    "epochs = 10\n",
    "best_loss = 10\n",
    "\n",
    "# call train and test function\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(data_loader=train_dataloader,\n",
    "                                       model=model,\n",
    "                                       loss_fn = loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       accuracy_fn=accuracy_fn,\n",
    "                                       device=device)\n",
    "    \n",
    "    test_loss, test_acc = test_step(data_loader=test_dataloader,\n",
    "                                    model=model,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    accuracy_fn=accuracy_fn,\n",
    "                                    device=device)\n",
    "    \n",
    "    for iteration, (x, y) in enumerate(train_dataloader):\n",
    "        iteration_loss_list.append(train_loss.item())\n",
    "        iteration_accuracy_list.append(train_acc)\n",
    "\n",
    "    \n",
    "    print(f\"Epoch: {epoch} | Training loss: {train_loss:.3f} | Training acc: {train_acc:.2f} | Test loss: {test_loss:.3f} | Test acc: {test_acc:.2f}\")\n",
    "\n",
    "    # save best model instance\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        print(f\"Saving best model for epoch: {epoch}\")\n",
    "        torch.save(obj=model.state_dict(), \n",
    "                   f=\"./model.pth\")     \n",
    "train_time_end_model = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_model,\n",
    "                                           end=train_time_end_model,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "342c394a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d45f4edcec4fd7a84b31a78deca6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training loss: 0.535 | Training acc: 81.12 | Test loss: 0.753 | Test acc: 78.71\n",
      "Saving best model for epoch: 0\n",
      "Epoch: 1 | Training loss: 0.233 | Training acc: 92.20 | Test loss: 0.614 | Test acc: 82.08\n",
      "Saving best model for epoch: 1\n",
      "Epoch: 2 | Training loss: 0.102 | Training acc: 96.52 | Test loss: 0.761 | Test acc: 80.36\n",
      "Epoch: 3 | Training loss: 0.080 | Training acc: 97.27 | Test loss: 0.685 | Test acc: 84.30\n",
      "Epoch: 4 | Training loss: 0.047 | Training acc: 98.41 | Test loss: 0.793 | Test acc: 84.81\n",
      "Epoch: 5 | Training loss: 0.044 | Training acc: 98.53 | Test loss: 0.667 | Test acc: 85.81\n",
      "Epoch: 6 | Training loss: 0.031 | Training acc: 98.94 | Test loss: 0.687 | Test acc: 86.01\n",
      "Epoch: 7 | Training loss: 0.026 | Training acc: 99.11 | Test loss: 0.699 | Test acc: 85.44\n",
      "Epoch: 8 | Training loss: 0.030 | Training acc: 99.03 | Test loss: 0.792 | Test acc: 85.76\n",
      "Epoch: 9 | Training loss: 0.021 | Training acc: 99.31 | Test loss: 0.750 | Test acc: 86.50\n",
      "Train time on cpu: 244.666 seconds\n"
     ]
    }
   ],
   "source": [
    "#CNN with Adam optimizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "data_flag = 'organamnist'\n",
    "info = INFO[data_flag]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "train_data = DataClass(split='train', transform=data_transform, download=True)\n",
    "val_data = DataClass(split='val', transform=data_transform, download=True)\n",
    "test_data = DataClass(split='test', transform=data_transform, download=True)\n",
    "\n",
    "# change data into dataloader form\n",
    "BATCH_SIZE = 128\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# define Model\n",
    "model = cnn(input_shape=n_channels, \n",
    "                     hidden_units=16,\n",
    "                     output_shape=n_classes).to(device)\n",
    "\n",
    "\n",
    "# setup loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# view Model\n",
    "# model\n",
    "\n",
    "# test performance\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# measure Time\n",
    "train_time_start_model = timer()\n",
    "iteration_loss_list = []\n",
    "iteration_accuracy_list = []\n",
    "\n",
    "# set parameters\n",
    "epochs = 10\n",
    "best_loss = 10\n",
    "\n",
    "# call train and test function\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(data_loader=train_dataloader,\n",
    "                                       model=model,\n",
    "                                       loss_fn = loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       accuracy_fn=accuracy_fn,\n",
    "                                       device=device)\n",
    "    \n",
    "    test_loss, test_acc = test_step(data_loader=test_dataloader,\n",
    "                                    model=model,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    accuracy_fn=accuracy_fn,\n",
    "                                    device=device)\n",
    "    \n",
    "    for iteration, (x, y) in enumerate(train_dataloader):\n",
    "        iteration_loss_list.append(train_loss.item())\n",
    "        iteration_accuracy_list.append(train_acc)\n",
    "\n",
    "    \n",
    "    print(f\"Epoch: {epoch} | Training loss: {train_loss:.3f} | Training acc: {train_acc:.2f} | Test loss: {test_loss:.3f} | Test acc: {test_acc:.2f}\")\n",
    "\n",
    "    # save best model instance\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        print(f\"Saving best model for epoch: {epoch}\")\n",
    "        torch.save(obj=model.state_dict(), \n",
    "                   f=\"./model.pth\")     \n",
    "train_time_end_model = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_model,\n",
    "                                           end=train_time_end_model,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e32ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
